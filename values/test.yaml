# helm install시 사용되는 config value는 노출되지 않도록 gitignore권장
# 이 파일은 샘플삼아 업로드

# helm install test https://github.com/YunanJeong/simple-kafka-deploy/releases/download/v2.0.3/skafka-2.0.3.tgz -f https://raw.githubusercontent.com/YunanJeong/simple-kafka-deploy/main/values/test.yaml

# helm install test skafka-2.0.3.tgz -f values/test.yaml


global:
  monitorDomain: "{{ .Release.Name }}.wai"
  imageRegistry: docker.io         # bitnami 계열 글로벌 

kafka:
  image:
    registry: docker.io

  # server.properties에 항목 추가
  extraConfig: |      
    ########################################################
    # 모든 replications.factor 관련 설정 방법

    # 브로커 수: n
    # replications.factor 권장값: n-1
    # replications.factor 허용값: n과 같거나 작아야 함 && 최소 1
    
    # 이미 생성된 topic의 replication.factor는 여기서 변경불가. kafka-reassign-partitions.sh 스크립트를 사용하여 수동변경 가능.
    # 중요한 topic일 수록 replication.factor가 크면 좋음(e.g. __consumer_offset, connect-offset 등 연결정보 토픽)
    ########################################################

    # __consumer_offset의 복제 수 (default: 3)
    offsets.topic.replication.factor=1

    # 신규생성 토픽의 파티션 수  (default: 1)
    num.partitions=1
    # 신규생성 토픽의 복제 수    (default: 1)
    # default.replication.factor=1
    # 신규생성 토픽의 segment(roll) 분할 기간 단위  (default: 7일)
    log.roll.ms=172800000

  listeners:
    client:
      protocol: PLAINTEXT          # SASL_PLAINTEXT, # https://github.com/bitnami/charts/issues/19128
    controller:
      protocol: PLAINTEXT          # SASL_PLAINTEXT
    interbroker:
      protocol: PLAINTEXT          # SASL_PLAINTEXT
    external:
      protocol: PLAINTEXT          # SASL_PLAINTEXT

    #  extraListeners=> bitnami/kafka의 _helpers.tpl 함수참고
    # extraListeners에 추가한 값은 advertisedListener 항목엔 자동추가되는데, listener엔 자동추가 안됨
    # 이 옵션 쓰려면 overrideListeners값에 listeners를 입력해줘야야함
    extraListeners: # [] ###test
      - name: CUSTOM
        containerPort: 9097
        protocol: PLAINTEXT
        sslClientAuth: ""

    # EXTERNAL에 한해서 각 브로커마다 advertised listener를 다르게(각 노드주소에맞게) 자동설정할 수 있다.
    # 이 헬름차트에선 EXTERNAL 말고는 전부 service 주소로 자동배치한다.
    # 각 노드마다 노드의 실제주소를 적어줘야하는데 override는 모든 노드에 적용되기 때문에 클러스터링 구성시 사용이 좀 힘듦
    
    # 실제 로드밸런서가 구축된 환경이라면 advertisedListener로 LB주소를 반환해줘도됨
    # 실제 로드밸런서가 없는 환경이라면 반환된 LB주소로 클라이언트가 접근해도 라우팅테이블이 없기 떄문에 엉뚱한 노드로 통신할 수 있음.

    # 결론: Kafka에서 포트별로 트래픽을 나누어 내부망접근, 외부망 접근을 구분하는 것은 가능하지만,
    # => 이 헬름차트로 구현하려면 매우 번거로운 편이다(특히, 클러스터링 구성시).
    # => 여러 경로의 외부접근(EXTERNAL)이 있을 것이라고 고려되지 않았음.
    advertisedListeners: "CUSTOM://172.31.60.204:30004,EXTERNAL://15.165.39.243:30003,CLIENT://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9092,INTERNAL://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9094"  
    # e.g. "EXTERNAL://172.19.0.126:30003,CLIENT://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9092,INTERNAL://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9094"
    overrideListeners: "CUSTOM://:9097,EXTERNAL://:9095,CLIENT://:9092,INTERNAL://:9094,CONTROLLER://:9093"

  # sals:
  # tls: 
  extraEnvVars: []                 # 환경변수 "추가"
  extraEnvVarsCM: ''
  extraEnvVarsSecret: ''
  extraVolumes: []
  extraVolumeMounts: []
  sidecars: []
  initContainers: []
  
  # controller: KRAFT모드 Broker
  controller:                      
    replicaCount: 1
    controllerOnly: false          # true: broker 기능을 포함하지 않는 controller 실행 
    zookeeperMigrationMode: false  # true: 주키퍼,크래프트 동시실행가능(마이그레이션목적)
    extraEnvVars: []               # Kafka Pod에 환경변수 "추가"
    affinity: {}
    nodeSelector: {}
    persistence:
      enabled: false               # production 배포시, true 필수
      size: 8Gi                    # 디스크 가용량의 70~80% 권장
      mountPath: /bitnami/kafka
    logPersistence:
      enabled: false
      size: 8Gi
      mountPath: /opt/bitnami/kafka/logs
  
  # broker: Zookeeper모드 Broker
  broker:                          
    replicaCount: 0
    zookeeperMigrationMode: false  # true: 주키퍼,크래프트 동시실행가능(마이그레이션목적)
    extraEnvVars: []               # Kafka Pod에 환경변수 "추가"
    affinity: {}
    nodeSelector: {}
    persistence:
      enabled: false               # production 배포시, true 필수
      size: 8Gi                    # 디스크 가용량의 70~80% 권장
      mountPath: /bitnami/kafka
    logPersistence:
      enabled: false
      size: 8Gi
      mountPath: /opt/bitnami/kafka/logs
  
  # 이 서비스는 외부접근을 모든 broker노드 중 하나로 랜덤 연결 시켜준다.
  # 첫 연결시에는 이 서비스로 접근하는게 적합하지만, 이후 지속연결동안은 특정 broker가 확정되어야 한다.
  # 따라서 advertised.listener는 이 서비스의 주소가 아닌, 아래 externalAccess로 설정된 특정 broker의 주소를 반환해야한다.
  service:
    type: LoadBalancer
    ports:
      client: 9092                 # "tcp-client"   (allows access from localhost machine)
      external: 9095               # "tcp-external" (requires externalAccess.enabled=true)
    extraPorts:    ###test
      - name: tcp-custom
        port: 9097
        targetPort: 9097
    nodePorts:
      client: ''
      external: ''
    loadbalancerIP: ''             # Managed Service 등 실제 LB가 있으면 입력. K3s의 가상 LB는 자동적용
    
  externalAccess:
    enabled: true                  # 위 "tcp-external"을 쓰려면 true 필요
    autoDiscovery:
      enabled: false               # false시, 아래 네트워크 섹션 직접 설정 필요(nodeports, loadBalancerIps, externalIps 등)
      image:
        registry: docker.io        # 오프라인 환경에서 docker.io프록시 or 사설registry로 설정                                
    
    # KRAFT모드 Broker의 externalAccess 설정
    controller:  
      service:                     # Broker 당 1개씩 생성되는 Service
        type: NodePort            
                                   ##################################################################################################
                                   # K8s기반 Kafka에서 외부 Client와 Broker 간 통신과정
                                     # 1. Client가 LoadBalancer의 주소(tcp-external)로 접근
                                     # 2. LoadBalancer는 Client의 최초 접근 트래픽을 Broker 1개에 랜덤매칭하여 포워딩  (K8s의 LoadBalancer 기능)
                                     # 3. 해당 Broker는 자신에게 직접 접근가능한 주소를 Kafka Client에게 전달          (Kafka의 advertised.listener 기능)
                                     # 4. Kafka Client는 connection이 유지되는 동안 Broker로부터 받은 주소로 통신

                                     # => kafka.service: 1번 과정의 "LoadBalancer 접근 방법"을 결정
                                     # => kakfa.externalAccess.controller.service: 4번 과정의 "개별 Broker 접근 방법"을 결정
                                   ##################################################################################################
                                   
                                   # externalAccess섹션은 [kafka server.properties의 advertised.listeners] 설정에 관여한다.
                                    
                                   # <kafka client가 "tcp-external"로 접근시 동작>
                                     # 첫번째 통신은 "tcp-external"포트를 사용
                                     # 이후 client는 advertised.listeners의 [EXTERNAL://IP:Port]로 통신
                                    
                                   # <네트워크 연결 검증시 주의 사항>
                                     # 1회성 통신인 [curl], [kcat토픽조회] 등은 advertised.listeners 주소를 사용하지 않으므로 externalAccess 설정에 오류가 있어도 정상 통신된다.
                                     # 2회 이상 통신하는 [kafka-topics.sh토픽조회], [produce], [consume] 등으로 테스트 필요
                                     
        ports:
          external: 9094           # "tcp-kafka"  (internally used)                 
        nodePorts: [30003] # , 30004, 30005]
                                   # broker 수 만큼 지정 (중복불가) # autoDiscovery 미사용시 필수 # e.g. [30003, 30004, 30005]  
        externalIPs: []            # broker 수 만큼 지정 # autoDiscovery 미사용시 설정 권장 # broker 별 실제 통신가능한 IP 직접 입력 (중복가능)
  
                                   # externalAccess Nodeport모드 && autoDiscovery 미사용 && externalIPs 미등록시
                                     # advertisedListener로 "EXTERNAL://{공인IP}:{개별nodeport}"가 자동등록된다.
                                     # EC2에선 괜찮지만, 일반적으로 공인IP를 통한 포트포워딩이 없으므로 사용불가
        extraPorts: # []  ###test
          - name: tcp-custom-public
            port: 9096
            targetPort: 9097 # tcp-custom # 9097
            nodePort: 30004
            # nodePort: "{{ index $.Values.externalAccess.controller.service.nodePorts $i }}"

    # Zookeeper모드 Broker의 externalAccess 설정 (섹션 동일)
    broker:                          
      service:
        type: LoadBalancer

  networkPolicy:
    enabled: false
  volumePermissions:
    enabled: false
  serviceAccount:
    create: true
  rbac: 
    create: true

  metrics:
    kafka:          
      enabled: false
      image:
        registry: docker.io  # bitnami/kafka-exporter
      containerPorts:
        metrics: 9308
    jmx:            
      enabled: false
      kafkaJmxPort: 5555
      image:
        registry: docker.io  # bitnami/jmx-exporter
      containerPorts:
        metrics: 5556
      service:
        ports:
          metrics: 5556
    serviceMonitor:          # bitnami/prometheus-operator 관련 설정
      enabled: false
    prometheusRule:
      enabled: false

  provisioning:
    enabled: false
    topics: []
    numPartitions: 1         # 초기 생성할 topic들의 partition 수 (broker의 default 설정 아님)
    replicationFactor: 1     # 초기 생성할 topic들의 replicationFactors (broker의 default 설정 아님)

  kraft:
    enabled: true
    clusterId: ""
  zookeeper:
    enabled: false
    replicaCount: 3
    persistence:
      enabled: false  # production시 true 필수
      size: 8Gi       # 충분 


connect:
  enabled: false
  replicaCount: 1
  image:
    repository: confluentinc/cp-kafka-connect     # registry 포함 표기 가능. 없으면 container runtime의 default
    pullPolicy: IfNotPresent
    tag: 7.2.2                                     
  configMapPairs:  # 지정된 KEY 외에도 커스텀 환경변수를 넘길 수 있음
    CONNECT_BOOTSTRAP_SERVERS: "{{ .Release.Name }}-kafka:9092"
    CONNECT_REST_PORT: "8083"
    # KAFKA_HEAP_OPTS: "-Xms4G -Xmx4G"
  extraVolumeMounts: # []
    - name: plugin
      mountPath: /usr/share/confluent-hub-components
  extraVolumes:      # []
    - name: plugin
      emptyDir: {}
  initContainers:    # []
    - name: init-plugin
      image: confluentinc/cp-kafka-connect:7.2.2  # curl, wget, tar, confluent-hub 가능
      command:
        - sh
        - -c
        - |
          # confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.4
          # confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.4
          # wget -P /usr/share/confluent-hub-components/confluentinc-kafka-connect-s3/ https://github.com/YunanJeong/kafka-connect-s3-without-topicname/releases/download/v10.5.0%2Bv1.0.0/topicless-timebasedpartitioner.jar
      volumeMounts:
        - name: plugin
          mountPath: /usr/share/confluent-hub-components

k8dashboard:
  enabled: true
  image:  # 글로벌 적용 불가
    registry: docker.io

ui4kafka:
  enabled: true
  image:  # 글로벌 적용 불가
    registry: docker.io

ingress:
  enabled: true
  annotations:
    spec.ingressClassName: traefik  # k3s default ingress controller
