# helm install시 사용되는 config value는 노출되지 않도록 gitignore권장
# 이 파일은 샘플삼아 업로드

global:
  monitorDomain: "{{ .Release.Name }}.wai"
  imageRegistry: docker.io         # bitnami 계열 글로벌 

kafka:
  image:
    registry: docker.io

  # server.properties에 항목 추가
  extraConfig: |      
               # __consumer_offsets 토픽의 replications 설정  # 브로커 수보다 크면 안되며, production시 1보다는 큰값 권장      
               offsets.topic.replication.factor=1 
               # topic default 설정 등 
               num.partitions=1 

  listeners:
    client:
      protocol: PLAINTEXT          # SASL_PLAINTEXT, # https://github.com/bitnami/charts/issues/19128
    controller:
      protocol: PLAINTEXT          # SASL_PLAINTEXT
    interbroker:
      protocol: PLAINTEXT          # SASL_PLAINTEXT
    external:
      protocol: PLAINTEXT          # SASL_PLAINTEXT
    extraListeners: []
    advertisedListeners: ''        # e.g. "EXTERNAL://172.19.0.126:30003,CLIENT://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9092,INTERNAL://test-kafka-controller-0.test-kafka-controller-headless.default.svc.cluster.local:9094"

  # sals:
  # tls: 
  extraEnvVars: []                 # 환경변수 "추가"
  extraEnvVarsCM: ''
  extraEnvVarsSecret: ''
  extraVolumes: []
  extraVolumeMounts: []
  sidecars: []
  initContainers: []
  
  # controller: KRAFT모드 Broker
  controller:                      
    replicaCount: 3
    controllerOnly: false          # true: broker 기능을 포함하지 않는 controller 실행 
    zookeeperMigrationMode: false  # true: 주키퍼,크래프트 동시실행가능(마이그레이션목적)
    extraEnvVars: []               # Kafka Pod에 환경변수 "추가"
    affinity: {}
    nodeSelector: {}
    persistence:
      enabled: false               # production 배포시, true 필수
      size: 8Gi                    # 디스크 가용량의 70~80% 권장
      mountPath: /bitnami/kafka
    logPersistence:
      enabled: false
      size: 8Gi
      mountPath: /opt/bitnami/kafka/logs
  
  # broker: Zookeeper모드 Broker
  broker:                          
    replicaCount: 0
    zookeeperMigrationMode: false  # true: 주키퍼,크래프트 동시실행가능(마이그레이션목적)
    extraEnvVars: []               # Kafka Pod에 환경변수 "추가"
    affinity: {}
    nodeSelector: {}
    persistence:
      enabled: false               # production 배포시, true 필수
      size: 8Gi                    # 디스크 가용량의 70~80% 권장
      mountPath: /bitnami/kafka
    logPersistence:
      enabled: false
      size: 8Gi
      mountPath: /opt/bitnami/kafka/logs
  
  service:
    type: LoadBalancer
    ports:
      client: 9092                 # "tcp-client"   (allows access from localhost machine)
      external: 9095               # "tcp-external" (requires externalAccess.enabled=true)
    nodePorts:
      client: ''
      external: ''
    loadbalancerIP: ''             # Managed Service 등 실제 LB가 있으면 입력. K3s의 가상 LB는 자동적용
    
  externalAccess:
    enabled: true                  # 위 "tcp-external"을 쓰려면 true 필요
    autoDiscovery:
      enabled: false               # false시, 아래 네트워크 섹션 직접 설정 필요(nodeports, loadBalancerIps, externalIps 등)
      image:
        registry: docker.io        # 오프라인 환경에서 docker.io프록시 or 사설registry로 설정                                
    
    # KRAFT모드 Broker의 externalAccess 설정
    controller:
      service:
        type: NodePort             # 실제 LB없으면, NodePort로 설정!!!
                                   # externalAccess에서 LoadBalancer로 설정하지않아도, kafka.service.type=LoadBalancer이면 Kafka는 LB 형식으로 배포된다.
                                   # externalAccess섹션은 개별 kafka노드를 어떻게 노출될 것인가를 결정한다.
                                     # But, Kafka Client가 개별 노드에 직접접근하기보다는 클러스터 내부설정 용도에 가깝다.
                                   # externalAccess섹션은 [kafka의 AdvertisedListener] 설정에 관여한다.
                                    
                                   # <kafka client가 "tcp-external"로 접근시 동작>
                                     # 첫번째 통신은 "tcp-external"포트를 사용
                                     # 이후 client는 AdvertisedListener를 받아, [EXTERNAL://IP:Port]로 통신
                                    
                                   # <네트워크 연결 확인시 주의 사항>
                                     # 1회성 통신인 [curl], [kcat토픽조회] 등은 AdvertisedListener를 사용하지않아서 externalAccess 설정이 잘못되어도 정상 통신된다.
                                     # 2회 이상 통신하는 [kafka-topics.sh토픽조회], [produce], [consume] 등으로 테스트가 필요

        ports:
          external: 9094           # "tcp-kafka"  (internally used)                 
        nodePorts: [30003, 30004, 30005]
                                   # broker 수 만큼 지정 (중복불가) # autoDiscovery 미사용시 필수 # e.g. [30003, 30004, 30005]  
        externalIPs: []            # broker 수 만큼 지정 # autoDiscovery 미사용시 설정 권장 # broker 별 실제 통신가능한 IP 직접 입력 (중복가능)
  
                                   # externalAccess Nodeport모드 && autoDiscovery 미사용 && externalIPs 미등록시
                                     # advertisedListener로 "EXTERNAL://{공인IP}:{개별nodeport}"가 자동등록된다.
                                     # EC2에선 괜찮지만, 일반적으로 공인IP를 통한 포트포워딩이 없으므로 사용불가
    
    # Zookeeper모드 Broker의 externalAccess 설정 (섹션 동일)
    broker:                          
      service:
        type: LoadBalancer

  networkPolicy:
    enabled: false
  volumePermissions:
    enabled: false
  serviceAccount:
    create: true
  rbac: 
    create: true

  metrics:
    kafka:          
      enabled: false
      image:
        registry: docker.io  # bitnami/kafka-exporter
      containerPorts:
        metrics: 9308
    jmx:            
      enabled: false
      kafkaJmxPort: 5555
      image:
        registry: docker.io  # bitnami/jmx-exporter
      containerPorts:
        metrics: 5556
      service:
        ports:
          metrics: 5556
    serviceMonitor:          # bitnami/prometheus-operator 관련 설정
      enabled: false
    prometheusRule:
      enabled: false

  provisioning:
    enabled: false
    topics: []
    numPartitions: 1         # 초기 생성할 topic들의 partition 수 (broker의 default 설정 아님)
    replicationFactor: 1     # 초기 생성할 topic들의 replicationFactors (broker의 default 설정 아님)

  kraft:
    enabled: true
    clusterId: ""
  zookeeper:
    enabled: false
    replicaCount: 3
    persistence:
      enabled: false  # production시 true 필수
      size: 8Gi       # 충분 


connect:
  enabled: true
  replicaCount: 1
  image:
    repository: confluentinc/cp-kafka-connect     # registry 포함 표기 가능. 없으면 container runtime의 default
    pullPolicy: IfNotPresent
    tag: 7.2.2                                     
  configMapPairs:  # 지정된 KEY 외에도 커스텀 환경변수를 넘길 수 있음
    CONNECT_BOOTSTRAP_SERVERS: "{{ .Release.Name }}-kafka:9092"
    CONNECT_REST_PORT: "8083"
    # KAFKA_HEAP_OPTS: "-Xms4G -Xmx4G"
  extraVolumeMounts: # []
    - name: plugin
      mountPath: /usr/share/confluent-hub-components
  extraVolumes:      # []
    - name: plugin
      emptyDir: {}
  initContainers:    # []
    - name: init-plugin
      image: confluentinc/cp-kafka-connect:7.2.2  # curl, wget, tar, confluent-hub 가능
      command:
        - sh
        - -c
        - |
          confluent-hub install --no-prompt confluentinc/kafka-connect-jdbc:10.7.4
          confluent-hub install --no-prompt confluentinc/kafka-connect-s3:10.5.4
          wget -P /usr/share/confluent-hub-components/confluentinc-kafka-connect-s3/ https://github.com/YunanJeong/kafka-connect-s3-without-topicname/releases/download/v10.5.0%2Bv1.0.0/topicless-timebasedpartitioner.jar
      volumeMounts:
        - name: plugin
          mountPath: /usr/share/confluent-hub-components

k8dashboard:
  enabled: true
  image:  # 글로벌 적용 불가
    registry: docker.io

ui4kafka:
  enabled: true
  image:  # 글로벌 적용 불가
    registry: docker.io

ingress:
  enabled: true
  annotations:
    spec.ingressClassName: traefik  # k3s default ingress controller
